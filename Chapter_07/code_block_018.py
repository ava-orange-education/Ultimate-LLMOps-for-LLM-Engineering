response = requests.post('http://localhost:11434/api/generate',
    json={
        "model": "llama2",
        "prompt": "Why use local LLMs?",
        "stream": False
    })
print(response.json()['response'])